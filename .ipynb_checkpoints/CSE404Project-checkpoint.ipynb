{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb26b63-9921-458f-a8e9-efdd2e7ff474",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'student-mat.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\u001b[0;32m---> 12\u001b[0m mat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent-mat.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m por \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudent-por.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m mat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcourse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'student-mat.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "mat = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "por = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "\n",
    "mat[\"course\"] = \"math\"\n",
    "por[\"course\"] = \"portuguese\"\n",
    "\n",
    "df = pd.concat([mat, por], ignore_index=True)\n",
    "\n",
    "df[\"pass\"] = (df[\"G3\"] >= 10).astype(int)\n",
    "\n",
    "# Drop grades to avoid leakage\n",
    "X = df.drop(columns=[\"G1\", \"G2\", \"G3\", \"pass\"])\n",
    "y = df[\"pass\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"lr\", LogisticRegression(max_iter=5000))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(name, X_split, y_true):\n",
    "    y_pred = clf.predict(X_split)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"F1       :\", f1_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    return y_pred, cm\n",
    "\n",
    "val_pred, _ = evaluate(\"VALIDATION\", X_val, y_val)\n",
    "test_pred, test_cm = evaluate(\"TEST\", X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(test_cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix (Test)\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0, 1], [\"Fail (0)\", \"Pass (1)\"])\n",
    "plt.yticks([0, 1], [\"Fail (0)\", \"Pass (1)\"])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, str(test_cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ohe = clf.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "cat_names = ohe.get_feature_names_out(cat_cols)\n",
    "feature_names = np.concatenate([num_cols.to_numpy(), cat_names])\n",
    "\n",
    "coefs = clf.named_steps[\"lr\"].coef_[0]\n",
    "\n",
    "top_k = 15\n",
    "top_idx = np.argsort(np.abs(coefs))[::-1][:top_k]\n",
    "\n",
    "top_features = feature_names[top_idx]\n",
    "top_coefs = coefs[top_idx]\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.barh(top_features, top_coefs)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 15 Logistic Regression Coefficients (by |coef|)\")\n",
    "plt.xlabel(\"Coefficient  ( + increases pass probability,  - decreases )\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 15 features:\")\n",
    "for f, c in zip(top_features, top_coefs):\n",
    "    print(f\"{f:35s}  {c:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133deeb-395b-4d3c-874d-f9ff82b1c9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd2181-24be-4bfc-811c-6c785bfbd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, StratifiedKFold, cross_val_predict\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, balanced_accuracy_score\n",
    ")\n",
    "\n",
    "# progress bar stuff\n",
    "from tqdm.auto import tqdm\n",
    "import joblib\n",
    "\n",
    "\n",
    "class TqdmJoblib(joblib.parallel.BatchCompletionCallBack):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.pbar = kwargs.pop(\"pbar\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.pbar.update(n=self.batch_size)\n",
    "        return super().__call__(*args, **kwargs)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "#  load + combine\n",
    "# ----------------------------\n",
    "df_mat = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "df_por = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "df = pd.concat([df_mat, df_por], ignore_index=True)\n",
    "\n",
    "# ----------------------------\n",
    "# label (pass/fail)\n",
    "# ----------------------------\n",
    "df[\"pass\"] = (df[\"G3\"] >= 10).astype(int)\n",
    "\n",
    "X = df.drop(columns=[\"G1\", \"G2\", \"G3\", \"pass\"])\n",
    "y = df[\"pass\"]\n",
    "\n",
    "print(\"shape:\", X.shape, flush=True)\n",
    "print(\"pass rate:\", y.mean(), flush=True)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"train:\", X_train.shape, \"val:\", X_val.shape, \"test:\", X_test.shape, flush=True)\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", prep),\n",
    "    (\"interactions\", PolynomialFeatures(\n",
    "        degree=2,\n",
    "        interaction_only=True,\n",
    "        include_bias=False\n",
    "    )),\n",
    "    (\"lr\", LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",            # required for elastic net\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=30000,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# 7) tune C + l1_ratio w/ 10-fold CV \n",
    "# ----------------------------\n",
    "param_grid = {\n",
    "    \"lr__C\": [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5],\n",
    "    \"lr__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "cv10 = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv10,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "n_candidates = len(param_grid[\"lr__C\"]) * len(param_grid[\"lr__l1_ratio\"])\n",
    "n_fits = n_candidates * cv10.get_n_splits()\n",
    "\n",
    "print(f\"\\nstarting gridsearch: {n_candidates} param combos x {cv10.get_n_splits()} folds = {n_fits} fits\", flush=True)\n",
    "\n",
    "with tqdm(total=n_fits, desc=\"gridsearch fits\", leave=True) as pbar:\n",
    "    old_cb = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = lambda *args, **kwargs: TqdmJoblib(*args, pbar=pbar, **kwargs)\n",
    "    try:\n",
    "        grid.fit(X_train, y_train)\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_cb\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "print(\"\\nbest params:\", grid.best_params_, flush=True)\n",
    "print(\"best cv balanced acc:\", grid.best_score_, flush=True)\n",
    "\n",
    "def eval_it(tag, X_split, y_true, thr=0.5):\n",
    "    probs = model.predict_proba(X_split)[:, 1]\n",
    "    preds = (probs >= thr).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    TN, FP = cm[0, 0], cm[0, 1]\n",
    "    fail_recall = TN / (TN + FP) if (TN + FP) else 0.0\n",
    "\n",
    "    print(\"\\n\" + tag)\n",
    "    print(\"threshold:\", round(thr, 3))\n",
    "    print(\"accuracy:\", round(accuracy_score(y_true, preds), 4))\n",
    "    print(\"balanced acc:\", round(balanced_accuracy_score(y_true, preds), 4))\n",
    "    print(\"precision (pass):\", round(precision_score(y_true, preds, zero_division=0), 4))\n",
    "    print(\"recall (pass):   \", round(recall_score(y_true, preds, zero_division=0), 4))\n",
    "    print(\"f1 (pass):       \", round(f1_score(y_true, preds, zero_division=0), 4))\n",
    "    print(\"recall (fail):   \", round(fail_recall, 4))\n",
    "    print(\"confusion matrix:\\n\", cm)\n",
    "\n",
    "    return probs, preds, cm\n",
    "\n",
    "# ----------------------------\n",
    "# 9) choose threshold using OUT-OF-FOLD probs on train (stable)\n",
    "# ----------------------------\n",
    "print(\"\\ngetting out-of-fold probs for threshold (this part can take a bit)...\", flush=True)\n",
    "\n",
    "oof_probs = cross_val_predict(\n",
    "    model, X_train, y_train,\n",
    "    cv=cv10,\n",
    "    method=\"predict_proba\",\n",
    "    n_jobs=-1\n",
    ")[:, 1]\n",
    "\n",
    "ths = np.linspace(0.1, 0.9, 81)\n",
    "\n",
    "best_thr = 0.5\n",
    "best_bal = -1\n",
    "\n",
    "for t in ths:\n",
    "    oof_pred = (oof_probs >= t).astype(int)\n",
    "    bal = balanced_accuracy_score(y_train, oof_pred)\n",
    "    if bal > best_bal:\n",
    "        best_bal = bal\n",
    "        best_thr = t\n",
    "\n",
    "print(\"\\nthreshold picked from OOF train preds:\", round(best_thr, 3), flush=True)\n",
    "print(\"OOF train balanced acc at that threshold:\", round(best_bal, 4), flush=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 10) final eval\n",
    "# ----------------------------\n",
    "_ = eval_it(\"VALIDATION (OOF threshold)\", X_val, y_val, thr=best_thr)\n",
    "test_probs, test_preds, test_cm = eval_it(\"TEST (OOF threshold)\", X_test, y_test, thr=best_thr)\n",
    "\n",
    "# ----------------------------\n",
    "# 11) plot confusion matrix (test)\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(test_cm, interpolation=\"nearest\")\n",
    "plt.title(\"confusion matrix (test)\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0, 1], [\"fail (0)\", \"pass (1)\"])\n",
    "plt.yticks([0, 1], [\"fail (0)\", \"pass (1)\"])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, str(test_cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 12) print top non-zero coefficients (includes interactions)\n",
    "# ----------------------------\n",
    "prep_fitted = model.named_steps[\"prep\"]\n",
    "poly_fitted = model.named_steps[\"interactions\"]\n",
    "lr_fitted = model.named_steps[\"lr\"]\n",
    "\n",
    "ohe = prep_fitted.named_transformers_[\"cat\"]\n",
    "cat_names = ohe.get_feature_names_out(cat_cols)\n",
    "base_feat_names = np.concatenate([num_cols.to_numpy(), cat_names])\n",
    "\n",
    "poly_feat_names = poly_fitted.get_feature_names_out(base_feat_names)\n",
    "\n",
    "coefs = lr_fitted.coef_[0]\n",
    "nz = np.where(coefs != 0)[0]\n",
    "\n",
    "print(\"\\nnon-zero features kept:\", len(nz), \"out of\", len(poly_feat_names), flush=True)\n",
    "\n",
    "top_k = 25\n",
    "top_idx = nz[np.argsort(np.abs(coefs[nz]))[::-1][:top_k]]\n",
    "\n",
    "print(\"\\ntop features (by |coef|):\", flush=True)\n",
    "for i in top_idx:\n",
    "    print(f\"{poly_feat_names[i]:55s}  {coefs[i]:+.4f}\")\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.barh(poly_feat_names[top_idx][::-1], coefs[top_idx][::-1])\n",
    "plt.title(\"top elastic net logistic regression coefficients (with interactions)\")\n",
    "plt.xlabel(\"coef  (+ helps pass, - hurts pass)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ae981-a707-4874-aeee-ffefcec85c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_recall_fail = 0.80 \n",
    "\n",
    "val_probs_pass = clf.predict_proba(X_val)[:, 1]\n",
    "# val_probs_pass = model.predict_proba(X_val)[:, 1]  # use this line instead if your estimator is named model\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "best_thr = None\n",
    "best_score = -1\n",
    "\n",
    "for thr in thresholds:\n",
    "    val_pred = (val_probs_pass >= thr).astype(int)  # 1=pass, 0=fail\n",
    "    cm = confusion_matrix(y_val, val_pred, labels=[0, 1])\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    # Recall for FAIL (class 0) = TN / (TN + FP)\n",
    "    recall_fail = TN / (TN + FP) if (TN + FP) else 0.0\n",
    "\n",
    "    if recall_fail >= target_recall_fail:\n",
    "        # pick whichever \"quality\" metric you want AFTER meeting the fail-recall requirement:\n",
    "        score = balanced_accuracy_score(y_val, val_pred)  # good default\n",
    "        # score = f1_score(y_val, val_pred, zero_division=0)  # alternative\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thr = thr\n",
    "\n",
    "if best_thr is None:\n",
    "    best_thr = 0.5\n",
    "    best_recall_fail = -1\n",
    "    for thr in thresholds:\n",
    "        val_pred = (val_probs_pass >= thr).astype(int)\n",
    "        cm = confusion_matrix(y_val, val_pred, labels=[0, 1])\n",
    "        TN, FP, FN, TP = cm.ravel()\n",
    "        recall_fail = TN / (TN + FP) if (TN + FP) else 0.0\n",
    "        if recall_fail > best_recall_fail:\n",
    "            best_recall_fail = recall_fail\n",
    "            best_thr = thr\n",
    "\n",
    "print(\"Chosen threshold (from VAL):\", round(best_thr, 3))\n",
    "print(\"VAL best balanced acc (subject to recall_fail target):\", round(best_score, 4) if best_score != -1 else \"N/A\")\n",
    "\n",
    "def report_split(tag, X_split, y_true, thr):\n",
    "    probs_pass = clf.predict_proba(X_split)[:, 1]\n",
    "    # probs_pass = model.predict_proba(X_split)[:, 1]  # use if estimator is named model\n",
    "    pred = (probs_pass >= thr).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, pred, labels=[0, 1])\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    recall_fail = TN / (TN + FP) if (TN + FP) else 0.0  # recall for fail (class 0)\n",
    "    recall_pass = TP / (TP + FN) if (TP + FN) else 0.0  # recall for pass (class 1)\n",
    "\n",
    "    print(\"\\n\" + tag)\n",
    "    print(\"thr:\", round(thr, 3))\n",
    "    print(\"accuracy:\", round(accuracy_score(y_true, pred), 4))\n",
    "    print(\"balanced acc:\", round(balanced_accuracy_score(y_true, pred), 4))\n",
    "    print(\"precision (pass=1):\", round(precision_score(y_true, pred, zero_division=0), 4))\n",
    "    print(\"recall (pass=1):   \", round(recall_pass, 4))\n",
    "    print(\"recall (fail=0):   \", round(recall_fail, 4))\n",
    "    print(\"f1 (pass=1):       \", round(f1_score(y_true, pred, zero_division=0), 4))\n",
    "    print(\"confusion matrix [ [TN FP], [FN TP] ]:\\n\", cm)\n",
    "\n",
    "report_split(\"VALIDATION (chosen thr)\", X_val, y_val, best_thr)\n",
    "report_split(\"TEST (chosen thr)\", X_test, y_test, best_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98deedf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
